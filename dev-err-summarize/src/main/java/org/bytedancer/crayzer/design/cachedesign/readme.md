## 缓存设计：缓存可以锦上添花也可以落井下石
### 不要把Redis当作数据库：N/A
**Redis 用作缓存，需要注意两点：**
- 第一，从客户端的角度来说，缓存数据的特点一定是有原始数据来源，且允许丢失，即使设置的缓存时间是 
1 分钟，在 30 秒时缓存数据因为某种原因消失了，也要能接受。当数据丢失后，需要从原始数据重新加载数
据，**不能认为缓存系统是绝对可靠的，更不能认为缓存系统不会删除没有过期的数据**。
- 第二，从 Redis 服务端的角度来说，缓存系统可以保存的数据量一定是小于原始数据的。
    - 首先，**应该限制 Redis 对内存的使用量**，也就是设置 maxmemory 参数；
    - 其次，**应该根据数据特点，明确 Redis 应该以怎样的算法来驱逐数据**。

**常用的数据淘汰策略**
- allkeys-lru，针对所有 Key，优先删除最近最少使用的 Key；
- volatile-lru，针对带有过期时间的 Key，优先删除最近最少使用的 Key；
- volatile-ttl，针对带有过期时间的 Key，优先删除即将过期的 Key（根据 TTL 的值）；
- allkeys-lfu（Redis 4.0 以上），针对所有 Key，优先删除最少使用的 Key；
- volatile-lfu（Redis 4.0 以上），针对带有过期时间的 Key，优先删除最少使用的 Key。

**如何选择合适的驱逐算法**
- **从算法角度来说，Redis 4.0 以后推出的 LFU 比 LRU 更“实用”**。试想一下，如果一个 Key 访问频率
是 1 天一次，但正好在 1 秒前刚访问过，那么 LRU 可能不会选择优先淘汰这个 Key，反而可能会淘汰一个 5 
秒访问一次但最近 2 秒没有访问过的 Key，而 LFU 算法不会有这个问题。而 TTL 会比较“头脑简单”一点，
优先删除即将过期的 Key，但有可能这个 Key 正在被大量访问。
- 然后，**从 Key 范围角度来说，allkeys 可以确保即使 Key 没有 TTL 也能回收**，如果使用的时候客户端
总是“忘记”设置缓存的过期时间，那么可以考虑使用这个系列的算法。而 volatile 会更稳妥一些，万一客户端
把 Redis 当做了长效缓存使用，只是启动时候初始化一次缓存，那么一旦删除了此类没有 TTL 的数据，可能
就会导致客户端出错。

### 注意缓存雪崩问题：cacheinvalid
> 由于缓存系统的 IOPS 比数据库高很多，因此要特别小心短时间内大量缓存失效的情况。这种情况一旦发生，
> 可能就会在瞬间有大量的数据需要回源到数据库查询，对数据库造成极大的压力，极限情况下甚至导致后端数
> 据库直接崩溃。这就是我们常说的缓存失效，也叫作缓存雪崩。

**从广义上说，产生缓存雪崩的原因有两种：**
- 第一种是，**缓存系统本身不可用**，导致大量请求直接回源到数据库；
    - 主要涉及缓存系统本身高可用的配置，不属于缓存设计层面的问题
- 第二种是，应用设计层面大量的 Key 在**同一时间过期**，导致大量的数据回源。

**解决缓存 Key 同时大规模失效需要回源，导致数据库压力激增问题的方式有两种**
- 方案一，**差异化缓存过期时间，不要让大量的 Key 在同一时间过期**。比如，在初始化缓存的时候，设置缓存
的过期时间是 30 秒 + 10 秒以内的随机延迟（扰动值）。这样，这些 Key 不会集中在 30 秒这个时刻过期，
而是会分散在 30~40 秒之间过期。
- 方案二，**让缓存不主动过期**。初始化缓存数据的时候设置缓存永不过期，然后启动一个后台线程 30 秒
一次定时把所有数据更新到缓存，而且通过适当的休眠，控制从数据库更新数据的频率，降低数据库压力。

**关于这两种解决方案，需要特别注意以下三点：**
- 方案一和方案二是截然不同的两种缓存方式，**如果无法全量缓存所有数据，那么只能使用方案一**；
- 即使使用了方案二，**缓存永不过期，同样需要在查询的时候，确保有回源的逻辑**。正如之前所说，无法确保
缓存系统中的数据永不丢失。
- 不管是方案一还是方案二，**在把数据从数据库加入缓存的时候，都需要判断来自数据库的数据是否合法**，比如
进行最基本的判空检查。

### 注意缓存击穿问题：cacheconcurrent
> 在某些 Key 属于极端热点数据，且并发量很大的情况下，如果这个 Key 过期，可能会在某个瞬间出现大量
> 的并发请求同时回源，相当于大量的并发请求直接打到了数据库。这种情况，就是常说的缓存击穿或缓存并
> 发问题。

如果回源操作特别昂贵，那么这种并发就不能忽略不计。这时，可以使用 Redisson 来获取一个基于 Redis 的
分布式锁，在查询数据库之前先尝试获取锁。

**在真实的业务场景下，不一定要这么严格地使用双重检查分布式锁进行全局的并发限制**，因为这样虽然可以把
数据库回源并发降到最低，但也限制了缓存失效时的并发。可以考虑的方式是：
- **方案一**，使用进程内的锁进行限制，这样每一个节点都可以以一个并发回源数据库；
- **方案二**，不使用锁进行限制，而是使用类似 Semaphore 的工具限制并发数，比如限制为 10，这样既限制了
回源并发数不至于太大，又能使得一定量的线程可以同时回源。

### 注意缓存穿透问题：cachepenetration
缓存中没有数据不一定代表数据没有缓存，**还有一种可能是原始数据压根就不存在**。如果这种漏洞被恶意利用
的话，就会对数据库造成很大的性能压力。这就是缓存穿透。

需要注意，缓存穿透和缓存击穿的区别：
- 缓存穿透是指，**缓存没有起到压力缓冲的作用**；
- 缓存击穿是指，**缓存失效时瞬时的并发打到数据库**。

**解决缓存穿透有以下两种方案：**
- 方案一，**对于不存在的数据，同样设置一个特殊的 Value 到缓存中**，比如当数据库中查出的用户信息为空的
时候，设置 NODATA 这样具有特殊含义的字符串到缓存中。这样下次请求缓存的时候还是可以命中缓存，即
直接从缓存返回结果，不查询数据库。
    - 可能会把大量无效的数据加入缓存中。 
- 方案二，即使用**布隆过滤器**做前置过滤。
    - 需要同步所有可能存在的值并加入布隆过滤器，这是比较麻烦的地方。
- 方案二可以和方案一同时使用，即将布隆过滤器前置，对于误判的情况再保存特殊值到缓存，双重保险避免
无效数据查询请求打到数据库。

布隆过滤器是一种概率型数据库结构，由一个很长的二进制向量和一系列随机映射函数组成。它的原理是，
当一个元素被加入集合时，通过 k 个散列函数将这个元素映射成一个 m 位 bit 数组中的 k 个点，并置为 1。
检索时，只要看看这些点是不是都是 1 就（大概）知道集合中有没有它了。**如果这些点有任何一个 0，则被检
元素一定不在；如果都是 1，则被检元素很可能在。**

**布隆过滤器不保存原始值，空间效率很高，**平均每一个元素占用 2.4 字节就可以达到万分之一的误判率。这里
的**误判率是指，过滤器判断值存在而实际并不存在的概率**。可以设置布隆过滤器使用更大的存储空间，来
得到更小的误判率。

**把所有可能的值保存在布隆过滤器中，从缓存读取数据前先过滤一次：**
- 如果布隆过滤器认为值不存在，那么值一定是不存在的，无需查询缓存也无需查询数据库；
- 对于极小概率的误判请求，才会最终让非法 Key 的请求走到缓存或数据库。

### 注意缓存数据同步策略：N/A
- 先更新缓存，再更新数据库；**策略不可行**
    - 数据库设计复杂，压力集中，数据库因为超时等原因更新操作失败的可能性较大；
    - **涉及事务**，很可能因为数据库更新失败，导致缓存和数据不一致
- 先更新数据库，再更新缓存；**策略不可行**
    - 一是，如果线程 A 和 B 先后完成数据库更新，但更新缓存时却是 B 和 A 的顺序，那很可能会把旧数据
    更新到缓存中引起数据不一致；
    - 二是，**不确定缓存中的数据是否会被访问**，不一定要把所有数据都更新到缓存中去。
- 先删除缓存，再更新数据库，访问的时候按需加载数据到缓存；**策略不可行**
    - **在并发的情况下**，很可能删除缓存后还没来得及更新数据库，就有另一个线程先读取了旧值到缓存中，
    如果并发量很大的话这个概率也会很大。
- **先更新数据库再删除缓存，访问的时候按需加载数据到缓存”策略是最好的。**
    - 虽然在极端情况下，这种策略也可能出现数据不一致的问题，但概率非常低，基本可以忽略。举一个“极
    端情况”的例子，比如更新数据的时间节点恰好是缓存失效的瞬间，这时 A 先读取到了旧值，随后在 B 操作数据库完成更新并且删除了缓存之后，A 再把旧值加入缓存。

需要注意的是，更新数据库后删除缓存的操作可能失败，如果失败则考虑把任务加入延迟队列进行延迟重试，
确保数据可以删除，缓存可以及时更新。因为删除操作是幂等的，所以即使重复删问题也不是太大，这又是删
除比更新好的一个原因。

因此，**针对缓存更新更推荐的方式是，缓存中的数据不由数据更新操作主动触发，统一在需要使用的时候按
需**加载，数据更新后及时删除缓存中的数据即可。